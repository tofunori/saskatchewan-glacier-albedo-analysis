"""
Gestionnaire de datasets MODIS
=============================

Ce module g√®re le chargement et la s√©lection entre les diff√©rents
produits MODIS (MCD43A3 vs MOD10A1) ainsi que la pr√©paration
des donn√©es pour les analyses comparatives.
"""

import pandas as pd
import numpy as np
import os
from pathlib import Path
import warnings

# Import from parent package
from ..config import (
    MCD43A3_CONFIG, MOD10A1_CONFIG, COMPARISON_CONFIG,
    FRACTION_CLASSES, get_dataset_config, get_available_datasets
)
from ..utils.helpers import print_section_header, validate_data
from .loader import SaskatchewanDataLoader

class DatasetManager:
    """
    Gestionnaire principal pour les datasets MODIS
    """
    
    def __init__(self):
        """
        Initialise le gestionnaire de datasets
        """
        self.datasets = {}
        self.current_dataset = None
        self.comparison_data = None
        
    def load_dataset(self, dataset_name, force_reload=False):
        """
        Charge un dataset sp√©cifique
        
        Args:
            dataset_name (str): 'MCD43A3' ou 'MOD10A1'
            force_reload (bool): Forcer le rechargement si d√©j√† en cache
            
        Returns:
            SaskatchewanDataLoader: Instance du chargeur de donn√©es
        """
        if not force_reload and dataset_name in self.datasets:
            print(f"‚úì Dataset {dataset_name} d√©j√† en cache")
            return self.datasets[dataset_name]
        
        print_section_header(f"Chargement du dataset {dataset_name}", level=2)
        
        # Obtenir la configuration
        config = get_dataset_config(dataset_name)
        
        # V√©rifier l'existence des fichiers
        if not os.path.exists(config['csv_path']):
            raise FileNotFoundError(f"Fichier CSV non trouv√©: {config['csv_path']}")
        
        # Cr√©er et charger les donn√©es
        loader = SaskatchewanDataLoader(config['csv_path'])
        loader.load_data()
        
        # Ajouter les m√©tadonn√©es du dataset
        loader.dataset_info = {
            'name': dataset_name,
            'config': config,
            'qa_available': os.path.exists(config['qa_csv_path']) if config['qa_csv_path'] else False
        }
        
        # Mettre en cache
        self.datasets[dataset_name] = loader
        self.current_dataset = dataset_name
        
        print(f"‚úì Dataset {dataset_name} charg√© avec succ√®s")
        loader.print_data_summary()
        
        return loader
    
    def get_dataset(self, dataset_name):
        """
        R√©cup√®re un dataset (le charge si n√©cessaire)
        
        Args:
            dataset_name (str): 'MCD43A3' ou 'MOD10A1'
            
        Returns:
            SaskatchewanDataLoader: Instance du chargeur de donn√©es
        """
        if dataset_name not in self.datasets:
            return self.load_dataset(dataset_name)
        return self.datasets[dataset_name]
    
    def load_qa_data(self, dataset_name):
        """
        Charge les donn√©es de qualit√© pour un dataset
        
        Args:
            dataset_name (str): 'MCD43A3' ou 'MOD10A1'
            
        Returns:
            pd.DataFrame: Donn√©es de qualit√©
        """
        config = get_dataset_config(dataset_name)
        
        if not config['qa_csv_path'] or not os.path.exists(config['qa_csv_path']):
            raise FileNotFoundError(f"Fichier QA non trouv√© pour {dataset_name}")
        
        print(f"üìä Chargement des donn√©es QA pour {dataset_name}...")
        qa_data = pd.read_csv(config['qa_csv_path'])
        
        # Convertir la date
        qa_data['date'] = pd.to_datetime(qa_data['date'])
        
        print(f"‚úì Donn√©es QA charg√©es: {len(qa_data)} observations")
        return qa_data
    
    def prepare_comparison_data(self, sync_dates=True):
        """
        Pr√©pare les donn√©es pour la comparaison entre MCD43A3 et MOD10A1
        
        Args:
            sync_dates (bool): Synchroniser les dates entre les datasets
            
        Returns:
            dict: Donn√©es comparatives avec cl√©s 'mcd43a3', 'mod10a1', 'merged'
        """
        print_section_header("Pr√©paration des donn√©es de comparaison", level=2)
        
        # Charger les deux datasets
        mcd43a3 = self.get_dataset('MCD43A3')
        mod10a1 = self.get_dataset('MOD10A1')
        
        if sync_dates:
            # Synchroniser les dates avec une tol√©rance
            merged_data = self._sync_datasets(mcd43a3.data, mod10a1.data)
        else:
            # Fusion simple sur les dates exactes
            merged_data = self._merge_datasets(mcd43a3.data, mod10a1.data)
        
        self.comparison_data = {
            'mcd43a3': mcd43a3.data,
            'mod10a1': mod10a1.data,
            'merged': merged_data,
            'sync_info': {
                'mcd43a3_total': len(mcd43a3.data),
                'mod10a1_total': len(mod10a1.data),
                'common_dates': len(merged_data),
                'sync_enabled': sync_dates
            }
        }
        
        print(f"‚úì Donn√©es de comparaison pr√©par√©es:")
        print(f"  - MCD43A3: {len(mcd43a3.data)} observations")
        print(f"  - MOD10A1: {len(mod10a1.data)} observations")
        print(f"  - Communes: {len(merged_data)} observations")
        
        return self.comparison_data
    
    def _sync_datasets(self, data1, data2, tolerance_days=1):
        """
        Synchronise deux datasets avec une tol√©rance de dates
        
        Args:
            data1 (pd.DataFrame): Premier dataset
            data2 (pd.DataFrame): Deuxi√®me dataset
            tolerance_days (int): Tol√©rance en jours
            
        Returns:
            pd.DataFrame: Donn√©es synchronis√©es
        """
        tolerance = pd.Timedelta(days=tolerance_days)
        merged_list = []
        
        # Pour chaque date dans data1, chercher la date la plus proche dans data2
        for _, row1 in data1.iterrows():
            date1 = row1['date']
            
            # Trouver les dates dans la fen√™tre de tol√©rance
            mask = abs(data2['date'] - date1) <= tolerance
            candidates = data2[mask]
            
            if not candidates.empty:
                # Prendre la date la plus proche
                closest_idx = (candidates['date'] - date1).abs().idxmin()
                row2 = data2.loc[closest_idx]
                
                # V√©rifier que au moins une fraction a des donn√©es valides dans les deux datasets
                has_valid_data = False
                for fraction in FRACTION_CLASSES:
                    col1 = f'{fraction}_mean'
                    col2 = f'{fraction}_mean'
                    
                    if (col1 in row1.index and col2 in row2.index and 
                        pd.notna(row1[col1]) and pd.notna(row2[col2])):
                        has_valid_data = True
                        break
                
                # Ne cr√©er la ligne combin√©e que si elle a des donn√©es valides
                if has_valid_data:
                    merged_row = self._merge_rows(row1, row2, 'mcd43a3', 'mod10a1')
                    merged_list.append(merged_row)
        
        if merged_list:
            return pd.DataFrame(merged_list)
        else:
            return pd.DataFrame()
    
    def _merge_datasets(self, data1, data2):
        """
        Fusion simple des datasets sur les dates exactes
        
        Args:
            data1 (pd.DataFrame): Premier dataset
            data2 (pd.DataFrame): Deuxi√®me dataset
            
        Returns:
            pd.DataFrame: Donn√©es fusionn√©es
        """
        # Renommer les colonnes pour √©viter les conflits
        data1_renamed = data1.copy()
        data2_renamed = data2.copy()
        
        # Identifier les colonnes de fractions
        fraction_cols = []
        for fraction in FRACTION_CLASSES:
            for var in ['mean', 'median', 'pixel_count', 'data_quality']:
                col = f'{fraction}_{var}'
                if col in data1.columns:
                    fraction_cols.append(col)
        
        # Renommer les colonnes de fractions
        rename_dict1 = {col: f'mcd43a3_{col}' for col in fraction_cols if col in data1.columns}
        rename_dict2 = {col: f'mod10a1_{col}' for col in fraction_cols if col in data2.columns}
        
        data1_renamed = data1_renamed.rename(columns=rename_dict1)
        data2_renamed = data2_renamed.rename(columns=rename_dict2)
        
        # Fusionner sur la date
        merged = pd.merge(
            data1_renamed,
            data2_renamed,
            on='date',
            how='inner',
            suffixes=('_mcd43a3', '_mod10a1')
        )
        
        # Filtrer pour ne garder que les lignes o√π les deux datasets ont des donn√©es valides
        # pour au moins une fraction
        valid_rows_mask = pd.Series([False] * len(merged))
        
        for fraction in FRACTION_CLASSES:
            mcd_col = f'mcd43a3_{fraction}_mean'
            mod_col = f'mod10a1_{fraction}_mean'
            
            if mcd_col in merged.columns and mod_col in merged.columns:
                # V√©rifier que les deux valeurs sont valides (non-NaN)
                fraction_valid = merged[mcd_col].notna() & merged[mod_col].notna()
                valid_rows_mask = valid_rows_mask | fraction_valid
        
        # Ne garder que les lignes avec au moins une fraction valide dans les deux datasets
        filtered_merged = merged[valid_rows_mask].copy()
        
        print(f"üìä Donn√©es filtr√©es: {len(merged)} ‚Üí {len(filtered_merged)} lignes avec donn√©es valides dans les deux produits")
        
        return filtered_merged
    
    def _merge_rows(self, row1, row2, prefix1, prefix2):
        """
        Fusionne deux lignes de donn√©es avec des pr√©fixes
        
        Args:
            row1, row2: Lignes de donn√©es pandas
            prefix1, prefix2: Pr√©fixes pour les colonnes
            
        Returns:
            dict: Ligne fusionn√©e
        """
        merged = {}
        
        # Colonnes temporelles communes
        temporal_cols = ['date', 'year', 'month', 'doy', 'decimal_year', 'season']
        for col in temporal_cols:
            if col in row1:
                merged[col] = row1[col]
        
        # Colonnes sp√©cifiques avec pr√©fixes
        for col, value in row1.items():
            if col not in temporal_cols:
                merged[f'{prefix1}_{col}'] = value
        
        for col, value in row2.items():
            if col not in temporal_cols:
                merged[f'{prefix2}_{col}'] = value
        
        return merged
    
    def get_comparison_summary(self):
        """
        Retourne un r√©sum√© des donn√©es de comparaison
        
        Returns:
            dict: R√©sum√© des comparaisons
        """
        if self.comparison_data is None:
            return {"error": "Donn√©es de comparaison non pr√©par√©es"}
        
        merged = self.comparison_data['merged']
        summary = {
            'total_common_dates': len(merged),
            'date_range': {
                'start': merged['date'].min(),
                'end': merged['date'].max()
            },
            'years_covered': sorted(merged['year'].unique()),
            'correlations': {},
            'differences': {}
        }
        
        # Calculer les corr√©lations par fraction
        for fraction in FRACTION_CLASSES:
            mcd_col = f'mcd43a3_{fraction}_mean'
            mod_col = f'mod10a1_{fraction}_mean'
            
            if mcd_col in merged.columns and mod_col in merged.columns:
                # Supprimer les NaN pour la corr√©lation
                valid_data = merged[[mcd_col, mod_col]].dropna()
                
                if len(valid_data) > 10:  # Minimum d'observations pour une corr√©lation fiable
                    corr = valid_data[mcd_col].corr(valid_data[mod_col])
                    diff_mean = (valid_data[mod_col] - valid_data[mcd_col]).mean()
                    diff_std = (valid_data[mod_col] - valid_data[mcd_col]).std()
                    
                    summary['correlations'][fraction] = {
                        'correlation': corr,
                        'n_observations': len(valid_data)
                    }
                    
                    summary['differences'][fraction] = {
                        'mean_difference': diff_mean,
                        'std_difference': diff_std,
                        'rmse': np.sqrt(((valid_data[mod_col] - valid_data[mcd_col]) ** 2).mean())
                    }
        
        return summary
    
    def print_comparison_summary(self):
        """
        Affiche un r√©sum√© des donn√©es de comparaison
        """
        summary = self.get_comparison_summary()
        
        if 'error' in summary:
            print(f"‚ùå {summary['error']}")
            return
        
        print_section_header("R√©sum√© de la comparaison MCD43A3 vs MOD10A1", level=2)
        print(f"üìä Dates communes: {summary['total_common_dates']}")
        print(f"üìÖ P√©riode: {summary['date_range']['start'].strftime('%Y-%m-%d')} ‚Üí {summary['date_range']['end'].strftime('%Y-%m-%d')}")
        print(f"üóìÔ∏è  Ann√©es: {len(summary['years_covered'])} ann√©es ({min(summary['years_covered'])}-{max(summary['years_covered'])})")
        
        print(f"\nüîó CORR√âLATIONS PAR FRACTION:")
        for fraction, stats in summary['correlations'].items():
            corr = stats['correlation']
            n_obs = stats['n_observations']
            quality = "üü¢ Forte" if corr > 0.8 else "üü° Mod√©r√©e" if corr > 0.6 else "üî¥ Faible"
            print(f"  {fraction}: r = {corr:.3f} ({quality}, n={n_obs})")
        
        print(f"\nüìè DIFF√âRENCES MOYENNES (MOD10A1 - MCD43A3):")
        for fraction, stats in summary['differences'].items():
            diff = stats['mean_difference']
            rmse = stats['rmse']
            trend = "üìà" if diff > 0.01 else "üìâ" if diff < -0.01 else "‚û°Ô∏è"
            print(f"  {fraction}: {diff:+.3f} ¬± {stats['std_difference']:.3f} (RMSE: {rmse:.3f}) {trend}")
    
    def list_available_datasets(self):
        """
        Affiche la liste des datasets disponibles
        """
        print_section_header("Datasets MODIS disponibles", level=2)
        
        datasets = get_available_datasets()
        for name, info in datasets.items():
            config = info['config']
            csv_status = "‚úÖ" if info['csv_exists'] else "‚ùå"
            qa_status = "‚úÖ" if info['qa_exists'] else "‚ùå"
            
            print(f"\nüìä {name} - {config['description']}")
            print(f"  Fichier principal: {csv_status}")
            print(f"  Fichier QA: {qa_status}")
            print(f"  R√©solution: {config['temporal_resolution']}")
            print(f"  √âchelle: {config['scaling_info']}")
    
    def get_dataset_for_analysis(self, dataset_choice):
        """
        Pr√©pare le dataset appropri√© pour l'analyse
        
        Args:
            dataset_choice (str): 'MCD43A3', 'MOD10A1', ou 'COMPARISON'
            
        Returns:
            Union[SaskatchewanDataLoader, dict]: Dataset ou donn√©es de comparaison
        """
        if dataset_choice in ['MCD43A3', 'MOD10A1']:
            return self.get_dataset(dataset_choice)
        elif dataset_choice == 'COMPARISON':
            return self.prepare_comparison_data()
        else:
            raise ValueError(f"Choix de dataset invalide: {dataset_choice}")